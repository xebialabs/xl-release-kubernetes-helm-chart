# Default values for xl-release.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

## Platform on which to install the chart (PlainK8s/AWSEKS/AzureAKS/GoogleGKE)
K8sSetup:
  Platform: PlainK8s
  validateValues: false

# No. of XL-Release master pods to run.
replicaCount: 3

## XL-Release image version
## Ref: https://hub.docker.com/r/xebialabs/xl-release/tags
ImageRepository: "xebialabs/xl-release"
ImageTag: "22.0"

## xebialabs/tiny-tools image version
## Ref: https://hub.docker.com/r/xebialabs/tiny-tools/tags
TinyToolsImageRepository: "xebialabs/tiny-tools"
TinyToolsImageTag: "22.2.0"

## Specify a imagePullPolicy
## Defaults to 'Always' if image tag is 'latest',set to 'IfNotPresent'
ImagePullPolicy: "Always"

## Secrets must be manually created in the namespace.
# ImagePullSecret: xlRelease

## @param appProtocol Release protocol (the protocol http or https that will be used by enduser to access Release). It is not used if ingress or route are enabled.
##
appProtocol: http
## @param appHostname Release hostname (the hostname that will be used by enduser to access Release). It is not used if ingress or route are enabled.
##
appHostname: ""

http2:
  enabled: false
ssl:
  enabled: false
  keystorePassword: 
  keystoreKeypassword: 
  keystore:

release:
  terminationGracePeriodSeconds: 200
  configurationManagement:
    configuration:
      enabled: true
      resetFiles: ## Resets part of the configuration files and license
        - xl-release-license.lic
        - xlr-wrapper-linux.conf
        - jmx-exporter.yaml
      script: |-
        cat example.txt && echo ""; # Add here commands to be executed before release start
      scriptData: ## Add here files that will be used by the configurationScript
        example.txt: |-
          Nothing to manage at this point.
    environment:
      enabled: true
      variables: {}
    volumeMounts:
      enabled: true
      paths: {}

keycloak:
  install: false
  extraEnv: |
    - name: PROXY_ADDRESS_FORWARDING
      value: "true"
    - name: KEYCLOAK_USER
      value: admin
    - name: KEYCLOAK_PASSWORD
      value: admin
    - name: JGROUPS_DISCOVERY_PROTOCOL
      value: dns.DNS_PING
    - name: JGROUPS_DISCOVERY_PROPERTIES
      value: 'dns_query={{ include "keycloak.serviceDnsName" . }}'
    - name: CACHE_OWNERS_COUNT
      value: "2"
    - name: CACHE_OWNERS_AUTH_SESSIONS_COUNT
      value: "2"
    - name: JAVA_OPTS
      value: >-
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=50.0
        -Djava.net.preferIPv4Stack=true
        -Djboss.modules.system.pkgs=$JBOSS_MODULES_SYSTEM_PKGS
        -Djava.awt.headless=true
    - name: DB_VENDOR
      value: postgres
    - name: DB_ADDR
      value: {{ .Release.Name }}-postgresql
    - name: DB_PORT
      value: "5432"
    - name: DB_DATABASE
      value: keycloak
    - name: DB_USER
      value: keycloak
    - name: DB_PASSWORD
      value: keycloak
    - name: KEYCLOAK_IMPORT
      value: /realm/digitalai-platform-realm.json
  extraVolumes: |
    - name: realm-config
      configMap:
        name: {{ .Release.Name }}-realm
  extraVolumeMounts: |
    - name: realm-config
      mountPath: "/realm/"
      readOnly: true
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx-dai-xlr
      nginx.ingress.kubernetes.io/ssl-redirect: "false"
    rules:
      - host: "keycloak.example.com"
        paths:
          - path: /
            pathType: Prefix
    tls: []
  postgresql:
    enabled: false
  service:
    type: LoadBalancer

oidc:
  enabled: false
  external: false
  clientId:
  clientSecret:
  clientAuthMethod:
  clientAuthJwt:
    enable: false
    jwsAlg:
    tokenKeyId:
    keyStore:
      enable: false
      path:
      password:
      type:
    key:
      enable: false
      alias:
      password:
  issuer:
  keyRetrievalUri:
  accessTokenUri:
  userAuthorizationUri:
  logoutUri:
  redirectUri:
  postLogoutRedirectUri:
  userNameClaim:
  fullNameClaim:
  emailClaim:
  externalIdClaim:
  rolesClaim:
  scopes:
  idTokenJWSAlg:
  accessToken:
    enable: false
    issuer:
    audience:
    keyRetrievalUri:
    jwsAlg:
    secretKey:
  proxyHost:
  proxyPort:
## Install nginx subchart. If you have nginx already installed, set 'install' to 'false'.
## If you have any other ingress controller installed, you can set the 'install' to 'false'.
## Ref: https://github.com/bitnami/charts/blob/master/bitnami/nginx-ingress-controller/README.md
nginx-ingress-controller:
  install: true
  image:
    pullSecrets: []
  replicaCount: 1
  resources:
    limits: {}
    #   cpu: 100m
    #   memory: 128Mi
    requests: {}
    #   cpu: 100m
    #   memory: 128Mi
  service:
    type: NodePort

haproxy-ingress:
  install: false

## Ingress Configuration
## Ref: https://kubernetes.io/docs/concepts/services-networking/ingress/
ingress:
  Enabled: true
  annotations:
    # ingress.kubernetes.io/tls-acme: "true"
    kubernetes.io/ingress.class: nginx-dai-xlr
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/affinity: cookie
    nginx.ingress.kubernetes.io/session-cookie-name: JSESSIONID
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "60"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "60"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "60"
  path: /
  hosts:
    - example.com

#  tls:
#    - secretName: example-secretsName
#      hosts:
#        - example.com

# https://docs.xebialabs.com/v.10.2/release/docker/docker-environment-variables/
AdminPassword:
# Provide the admin password to be used

xlrLicense:
# Convert xl-release.lic files content to base64 ( cat xl-release.lic | base64 -w 0 ) and put the output here

RepositoryKeystore:
# https://docs.xebialabs.com/v.10.2/release/how-to/changing-passwords-in-xl-release/
# Convert repository-keystore.jceks files content to base64 ( cat repository-keystore.jceks | base64 -w 0 ) and put the output here

KeystorePassphrase:
# Passphrase for repository-keystore.jceks file

## Ref: https://github.com/bitnami/charts/blob/master/bitnami/postgresql/README.md
## Install postgresql chart. If you have an existing database deployment, set 'install' to 'false'.
postgresql:
  install: true
  initdbScriptsSecret: "postgresql-init-sql-xlr"
  image:
    debug: true
    pullSecrets: []
  persistence:
    enabled: true
    storageClass: "-"
    size: 8Gi
    existingClaim: ""
  postgresqlUsername: postgres
  postgresqlPassword: ""
  postgresqlMaxConnections: "150"
  service:
    type: ClusterIP
    port: 5432
  resources:
    requests:
      memory: 256Mi
      cpu: 250m

GenerateXlConfig: true
MetricsEnabled: false
UseIpAsHostname: false
ForceRemoveMissingTypes: false

## Ref: https://docs.xebialabs.com/v.10.2/release/how-to/configure-the-xl-release-sql-repository-in-a-database/#configuration-examples
UseExistingDB:
  Enabled: false
  # If you want to use a existing database, change 'postgresql.install' to 'false'.
  # Set 'UseExistingDB.Enabled' to 'true'.Uncomment the following lines and provide the values.
  # XLR_DB_URL:
  # XLR_DB_USER:
  # XLR_DB_PASS:
  # XLR_REPORT_DB_URL:
  # XLR_REPORT_DB_USER:
  # XLR_REPORT_DB_PASS:

## Install rabbitmq chart. If you have an existing message queue deployment, set 'install' to 'false'.
## ref: https://github.com/bitnami/charts/blob/master/bitnami/rabbitmq/README.md
rabbitmq:
  install: true
  forceBoot: true
  replicaCount: 3
  image:
    debug: true
    pullSecrets: []
  auth:
    username: guest
    password: guest
    erlangCookie: RELEASERABBITMQCLUSTER
  extraPlugins: 'rabbitmq_amqp1_0'
  extraSecrets:
    xlr-load-definition:
      xlr-load_definition.json: |
        {
        "users": [
          {
              "name": "{{ .Values.auth.username }}",
              "password": "{{ .Values.auth.password }}",
              "tags": "administrator"
          }
          ],
        "vhosts": [
          {
            "name": "/"
          }
          ],
          "permissions": [
          {
            "user": "{{ .Values.auth.username }}",
            "vhost": "/",
            "configure": ".*",
            "write": ".*",
            "read": ".*"
          }
          ],
        "global_parameters": [
          {
            "name": "cluster_name",
            "value": ""
          }
          ],
         "policies": [
            {
              "name": "ha-all",
              "apply-to": "all",
              "pattern": ".*",
              "vhost": "/",
              "definition": {
                "ha-mode": "all",
                "ha-sync-mode": "automatic",
                "ha-sync-batch-size": 1
              }
            }
          ]
        }
  loadDefinition:
    enabled: true
    existingSecret: xlr-load-definition
  extraConfiguration: |
    load_definitions = /app/xlr-load_definition.json
    raft.wal_max_size_bytes = 1048576
  persistence:
    enabled: true
    storageClass: "-"
    size: 8Gi
  service:
    type: ClusterIP
  volumePermissions:
    enabled: true

## Ref: https://docs.xebialabs.com/v.10.2/release/webhooks/webhooks-overview/
UseExistingMQ:
  Enabled: false
  # If you want to use a existing Message Queue, change 'rabbitmq.install' to 'false'.
  # Set 'UseExistingMQ.Enabled' to 'true'.Uncomment the following lines and provide the values.
  # XLR_TASK_QUEUE_USERNAME:
  # XLR_TASK_QUEUE_PASSWORD:
  # XLR_TASK_QUEUE_NAME:
  # XLR_TASK_QUEUE_URL:

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 3
  #  memory: 3Gi
  # requests:
  #  cpu: 0.7
  #  memory: 1700Mi

## Configure extra options for liveness and readiness probes
HealthProbes: true
HealthProbesLivenessTimeout: 60
HealthProbesReadinessTimeout: 60
HealthProbeFailureThreshold: 12
HealthPeriodScans: 10

nodeSelector: {}

tolerations: []

## Affinity and anti-affinity
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
affinity: {}

## XL Release data Persistent Volume for 'XL Release Report'
## If "Persistence.Enabled" set to "false", it will use hostPath.
Persistence:
  Enabled: true
  ## Choose storage class provided by your cloud provider, example "ssd" on GKE, AWS and OpenStack
  StorageClass: "-"
  Annotations: {}
  AccessMode: ReadWriteOnce
  Size: 8Gi
  Paths:
    - /opt/xebialabs/xl-release-server/reports
    - /opt/xebialabs/xl-release-server/work
    - /opt/xebialabs/xl-release-server/conf
    - /opt/xebialabs/xl-release-server/ext
    - /opt/xebialabs/xl-release-server/hotfix
    - /opt/xebialabs/xl-release-server/hotfix/lib
    - /opt/xebialabs/xl-release-server/hotfix/plugins
    - /opt/xebialabs/xl-release-server/log

## Release pods' Security Context
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
## @param podSecurityContext.enabled Enable Release pod's Security Context
## @param podSecurityContext.runAsUser Set Release pod's Security Context runAsUser
## @param podSecurityContext.runAsGroup Set Release pod's Security Context runAsGroup
## @param podSecurityContext.fsGroup Set Release pod's Security Context fsGroup
##
podSecurityContext:
  enabled: true
  runAsUser: 10001
  runAsGroup: 10001
  fsGroup: 10001

## @param containerSecurityContext.enabled Enabled Release containers' Security Context
## @param containerSecurityContext.runAsUser Set Release containers' Security Context runAsUser
## @param containerSecurityContext.runAsNonRoot Set Release container's Security Context runAsNonRoot
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
## Example:
##   containerSecurityContext:
##     capabilities:
##       drop: ["NET_RAW"]
##     readOnlyRootFilesystem: true
##
containerSecurityContext:
  enabled: true
  runAsUser: 10001
  runAsNonRoot: true

## Init Container parameters
## Change the owner and group of the persistent volume(s) mountpoint(s) to 'runAsUser:fsGroup' on each component
## values from the securityContext section of the component
##
volumePermissions:
  ## @param volumePermissions.enabled Enable init container that changes the owner and group of the persistent volume(s) mountpoint to `runAsUser:fsGroup`
  ##
  enabled: false
  ## @param volumePermissions.script Script for changing the owner and group of the persistent volume(s). Paths are declared in the 'paths' variable.
  script: |
    paths="{{ range $path := .Values.Persistence.Paths }}{{ $path }} {{ end }}"
    for path in "${paths}"; do
      echo "Changing ownership to {{ .Values.containerSecurityContext.runAsUser }}:{{ .Values.podSecurityContext.fsGroup }} for ${path}"
      chown "{{ .Values.containerSecurityContext.runAsUser }}:{{ .Values.podSecurityContext.fsGroup }}" "${path}"
      find "${path}" -mindepth 1 -maxdepth 1 -not -name ".snapshot" -not -name "lost+found" | \
        xargs -r chown -R "{{ .Values.containerSecurityContext.runAsUser }}:{{ .Values.podSecurityContext.fsGroup }}"
    done
  ## Init container' Security Context
  ## Note: the chown of the data folder is done to containerSecurityContext.runAsUser
  ## and not the below volumePermissions.containerSecurityContext.runAsUser
  ## @param volumePermissions.containerSecurityContext.runAsUser User ID for the init container
  ##
  containerSecurityContext:
    runAsUser: 0
